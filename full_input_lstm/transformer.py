"""
NOTE: Starter code generated by gpt-o4
"""
import torch
import torch.nn as nn
import math

from constants import FUTURE_STEPS

class PositionalEncoding(nn.Module):
    """Sinusoidal positional encoding, as in Vaswani et al."""
    def __init__(self, d_model, max_len=5000):
        super().__init__()
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len).unsqueeze(1).float()
        div_term = torch.exp(torch.arange(0, d_model, 2).float() *
                             -(math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0)  # shape (1, max_len, d_model)
        self.register_buffer('pe', pe)

    def forward(self, x):
        # x: (batch, seq_len, d_model)
        seq_len = x.size(1)
        return x + self.pe[:, :seq_len]  # broadcast over batch


class CrossAgentTransformerPredictor(nn.Module):
    def __init__(self,
                 num_features: int,
                 d_model: int = 16,
                 nhead: int = 4,
                 num_layers: int = 2,
                 dim_feedforward: int = 128,
                 dropout: float = 0.1,
                 future_steps: int = FUTURE_STEPS,
                 output_dim: int = None):
        super().__init__()
        self.output_dim = output_dim or num_features
        self.future_steps = future_steps

        # 1) Project raw features → model dimension
        self.input_proj = nn.Linear(num_features, d_model)
        # 2) Positional encoding over (agent × time) tokens
        self.pos_encoder = PositionalEncoding(d_model)
        # 3) Transformer encoder
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=dim_feedforward,
            dropout=dropout,
            activation='relu'
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)
        self.reconstruct = nn.Linear(d_model, self.output_dim)
        self.forecast = nn.Linear(d_model, self.future_steps * self.output_dim)

    def forward(self, input_data):
        """
        x: (B, A, T, F)
        returns:
          • recon: (B, A, T, output_dim)       — reconstruct input
          • fut  : (B, A, future_steps, output_dim) — forecast
        """
        if hasattr(input_data, "x") and hasattr(input_data, "num_graphs"):
            n_agents, seq_len, d_in = 50, 50, 6
            x = input_data.x.view(input_data.num_graphs, n_agents, seq_len, d_in)
        else:
            x = input_data
        # Only consider one second of time
        x = x[:, :, -10:, :]
        B, A, T, F = x.shape

        # 1) merge agent×time
        x = self.input_proj(x)            # → (B, A, T, d_model)
        x = x.view(B, A*T, -1)            # → (B, A*T, d_model)
        x = self.pos_encoder(x)           # → (B, A*T, d_model)
        x = x.transpose(0, 1)             # → (A*T, B, d_model)
        h = self.transformer(x)               # → (A*T, B, d_model)
        h = h.transpose(0, 1)             # → (B, A*T, d_model)
        h = h.view(B, A, T, -1)           # → (B, A, T, d_model)

        # 2) reconstruction at each step
        recon = self.reconstruct(h)       # → (B, A, T, output_dim)

        # 3) forecasting from last time-step
        last = h[:, :, -1, :]             # → (B, A, d_model)
        fut  = self.forecast(last)        # → (B, A, future_steps*output_dim)
        #fut  = fut.view(B, A, self.future_steps, self.output_dim)
        fut  = fut.view(B, A, self.output_dim)
        return fut

class AutoRegressiveMLP(nn.Module):
    def __init__(self,
                 num_features: int,
                 hidden_dim: int = 64,
                 output_dim: int = None,
                 future_steps: int = FUTURE_STEPS):
        """
        :param num_features: number of input features per timestep (F)
        :param hidden_dim:   dimensionality of the MLP’s hidden layers
        :param output_dim:   per‐feature output dim (defaults to num_features)
        :param future_steps: how many steps ahead to forecast (kept simple here)
        """
        super().__init__()
        self.output_dim   = output_dim or num_features
        self.future_steps = future_steps

        # 1) project raw features → hidden_dim
        self.input_proj = nn.Linear(num_features, hidden_dim)

        # 2) a tiny MLP applied per “agent×time token”
        self.mlp = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(inplace=True),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(inplace=True),
        )

        # 3) head to reconstruct each input step (optional)
        self.reconstruct = nn.Linear(hidden_dim, self.output_dim)

        # 4) head to forecast future_steps
        self.forecast = nn.Linear(hidden_dim, future_steps * self.output_dim)

    def forward(self, input_data):
        """
        x: Tensor of shape (B, A, T, F), or a DataBatch with .x & .num_graphs
        returns:
          • recon: (B, A, T, output_dim)
          • fut  : (B, A, future_steps, output_dim)
        """
        # --- unpack DataBatch if needed ---
        if hasattr(input_data, "x") and hasattr(input_data, "num_graphs"):
            # assume every graph has A=50 agents, T=50 timesteps, F=6 features
            B = input_data.num_graphs
            A, T, F = 50, 50, 6
            x = input_data.x.view(B, A, T, F)
        else:
            x = input_data  # already (B, A, T, F)

        # only keep the last 10 steps (as in your example)
        x = x[:, :, -10:, :]       # → (B, A, T′=10, F)
        B, A, T, F = x.shape

        # 1) project & flatten agent×time into tokens
        x = self.input_proj(x)     # → (B, A, T, hidden_dim)
        x = x.view(B, A * T, -1)   # → (B, A*T, hidden_dim)

        # 2) per‐token MLP
        h = self.mlp(x)            # → (B, A*T, hidden_dim)

        # 3) reshape back to (B, A, T, hidden_dim)
        h = h.view(B, A, T, -1)

        # 4) reconstruct
        recon = self.reconstruct(h)   # → (B, A, T, output_dim)

        # 5) forecast from the last time‐step
        last = h[:, :, -1, :]                                     # (B, A, hidden_dim)
        fut  = self.forecast(last)                                # (B, A, future_steps*output_dim)
        fut  = fut.view(B, A, self.future_steps, self.output_dim) # (B, A, future_steps, output_dim)

        return fut.squeeze(2)


# === Example usage ===
if __name__ == "__main__":
    batch_size = 8
    num_agents = 5
    seq_length = 20
    num_features = 6

    model = CrossAgentTransformerPredictor(
        num_features=num_features,
        d_model=32,
        nhead=4,
        num_layers=1,
        dim_feedforward=64,
        dropout=0.1,
    )

    dummy_input = torch.rand(batch_size, num_agents, seq_length, num_features)
    output = model(dummy_input)
    print("Output shape:", output.shape)
    # → Output shape: (8, 5, 20, 6)

